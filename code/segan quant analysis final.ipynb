{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d86993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import PReLU\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from sigma import get_glottal\n",
    "from time import time\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370c11fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(r'C:\\Users\\user\\Desktop\\segan_model_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015d8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_egg(speech):\n",
    "    \n",
    "    dataset = sliding_window_view(speech, 2048)[::1024, :]\n",
    "    \n",
    "    n = int((len(speech) - 2048)/1024) + 1\n",
    "    \n",
    "    egg_windows = model.predict(dataset)[:,:,0]\n",
    "    \n",
    "    hann = 0.5*(1 - np.cos(np.pi*np.arange(2048)/1024))\n",
    "    \n",
    "    egg_windows[1:-1] = egg_windows[1:-1]*hann\n",
    "    \n",
    "    egg_windows[0,1024:] = egg_windows[0,1024:]*hann[1024:]\n",
    "    \n",
    "    egg_windows[-1,:1024] = egg_windows[-1,:1024]*hann[:1024]\n",
    "    \n",
    "    egg_reconstructed = np.zeros(2048 + (n-1)*1024)\n",
    "    \n",
    "    for i in range(n):\n",
    "        egg_reconstructed[1024*i:1024*i+2048] = egg_reconstructed[1024*i:1024*i+2048] + egg_windows[i]\n",
    "        \n",
    "    return egg_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0927691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naylor_metrics(ref_signal, est_signal):\n",
    "\n",
    "    assert (np.squeeze(ref_signal).ndim == 1)\n",
    "    assert (np.squeeze(est_signal).ndim == 1)\n",
    "\n",
    "    ref_signal = np.squeeze(ref_signal)\n",
    "    est_signal = np.squeeze(est_signal)\n",
    "\n",
    "    min_f0 = 50\n",
    "    max_f0 = 500\n",
    "    min_glottal_cycle = 1 / max_f0\n",
    "    max_glottal_cycle = 1 / min_f0\n",
    "\n",
    "    nHit = 0\n",
    "    nMiss = 0\n",
    "    nFalse = 0\n",
    "    nCycles = 0\n",
    "    highNumCycles = 100000\n",
    "    estimation_distance = np.full(highNumCycles, np.nan)\n",
    "\n",
    "    ref_fwdiffs = np.diff(ref_signal)[1:]\n",
    "    ref_bwdiffs = np.diff(ref_signal)[:-1]\n",
    "\n",
    "    for i in range(len(ref_fwdiffs)):\n",
    "        ref_cur_sample = ref_signal[i + 1]\n",
    "        ref_dist_fw = ref_fwdiffs[i]\n",
    "        ref_dist_bw = ref_bwdiffs[i]\n",
    "\n",
    "        dist_in_allowed_range = min_glottal_cycle <= ref_dist_fw <= max_glottal_cycle and min_glottal_cycle <= ref_dist_bw <= max_glottal_cycle\n",
    "        if dist_in_allowed_range:\n",
    "\n",
    "            cycle_start = ref_cur_sample - ref_dist_bw / 2\n",
    "            cycle_stop = ref_cur_sample + ref_dist_fw / 2\n",
    "\n",
    "            est_GCIs_in_cycle = est_signal[np.logical_and(est_signal > cycle_start, est_signal < cycle_stop)]\n",
    "            n_est_in_cycle = np.count_nonzero(est_GCIs_in_cycle)\n",
    "\n",
    "            nCycles += 1\n",
    "\n",
    "            if n_est_in_cycle == 1:\n",
    "                nHit += 1\n",
    "                estimation_distance[nHit] = est_GCIs_in_cycle[0] - ref_cur_sample\n",
    "            elif n_est_in_cycle < 1:\n",
    "                nMiss += 1\n",
    "            else:\n",
    "                nFalse += 1\n",
    "\n",
    "    estimation_distance = estimation_distance[np.invert(np.isnan(estimation_distance))]\n",
    "    \n",
    "    try:\n",
    "        identification_rate = nHit / nCycles\n",
    "    except:\n",
    "        return {'identification_rate' : -1}\n",
    "    else:\n",
    "        identification_rate = nHit / nCycles\n",
    "        miss_rate = nMiss / nCycles\n",
    "        false_alarm_rate = nFalse / nCycles\n",
    "        identification_accuracy = 0 if np.size(estimation_distance) == 0 else np.std(estimation_distance)\n",
    "    \n",
    "\n",
    "        return {\n",
    "            'identification_rate': identification_rate,\n",
    "            'miss_rate': miss_rate,\n",
    "            'false_alarm_rate': false_alarm_rate,\n",
    "            'identification_accuracy': identification_accuracy\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff5fca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee1dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 235.17610239982605\n"
     ]
    }
   ],
   "source": [
    "dataset = r'C:\\Users\\user\\Desktop\\dataset'\n",
    "\n",
    "identification_rate_gci = 0\n",
    "miss_rate_gci = 0\n",
    "false_alarm_rate_gci = 0\n",
    "identification_accuracy_gci = 0\n",
    "\n",
    "identification_rate_goi = 0\n",
    "miss_rate_goi = 0\n",
    "false_alarm_rate_goi = 0\n",
    "identification_accuracy_goi = 0\n",
    "\n",
    "n = 0\n",
    "\n",
    "t1 = time()\n",
    "k = os.listdir(dataset + r\"\\speech\")\n",
    "np.random.shuffle(k)\n",
    "for i in k:\n",
    "    if i[:3] == \"bdl\":\n",
    "\n",
    "        n += 1\n",
    "\n",
    "        egg,sr_egg = librosa.load(dataset + r\"\\egg\" + \"\\\\\" + i)\n",
    "        speech,_ = librosa.load(dataset + r\"\\speech\" + \"\\\\\" + i)\n",
    "\n",
    "        egg_recreated = reconstruct_egg(speech)\n",
    "        egg = egg[:len(egg_recreated)]\n",
    "\n",
    "        egg_low_pass = butter_lowpass_filter(egg_recreated, cutoff = 1000, fs = sr_egg, order = 6)\n",
    "\n",
    "        gci,goi = get_glottal(egg,sr_egg)\n",
    "        gci_rec,goi_rec = get_glottal(egg_low_pass,sr_egg)\n",
    "\n",
    "        maximum = np.amax((np.amax(gci),np.amax(gci_rec)))\n",
    "        val = naylor_metrics(gci/maximum, gci_rec/maximum)\n",
    "        \n",
    "        if val[\"identification_rate\"] == -1:\n",
    "            n -= 1\n",
    "            continue\n",
    "\n",
    "        identification_rate_gci += val[\"identification_rate\"]\n",
    "        miss_rate_gci += val[\"miss_rate\"]\n",
    "        false_alarm_rate_gci += val[\"false_alarm_rate\"]\n",
    "        identification_accuracy_gci += val[\"identification_accuracy\"]\n",
    "\n",
    "        maximum = np.amax((np.amax(goi),np.amax(goi_rec)))\n",
    "        val = naylor_metrics(goi/maximum, goi_rec/maximum)\n",
    "        \n",
    "        if val[\"identification_rate\"] == -1:\n",
    "            n -= 1\n",
    "            continue\n",
    "\n",
    "        identification_rate_goi += val[\"identification_rate\"]\n",
    "        miss_rate_goi += val[\"miss_rate\"]\n",
    "        false_alarm_rate_goi += val[\"false_alarm_rate\"]\n",
    "        identification_accuracy_goi += val[\"identification_accuracy\"]\n",
    "\n",
    "        if n==50:\n",
    "            break\n",
    "        \n",
    "for i in k:\n",
    "    if i[:3] == \"jmk\":\n",
    "\n",
    "        n += 1\n",
    "\n",
    "        egg,sr_egg = librosa.load(dataset + r\"\\egg\" + \"\\\\\" + i)\n",
    "        speech,_ = librosa.load(dataset + r\"\\speech\" + \"\\\\\" + i)\n",
    "\n",
    "        egg_recreated = reconstruct_egg(speech)\n",
    "        egg = egg[:len(egg_recreated)]\n",
    "\n",
    "        egg_low_pass = butter_lowpass_filter(egg_recreated, cutoff = 1000, fs = sr_egg, order = 6)\n",
    "\n",
    "        gci,goi = get_glottal(egg,sr_egg)\n",
    "        gci_rec,goi_rec = get_glottal(egg_low_pass,sr_egg)\n",
    "\n",
    "        maximum = np.amax((np.amax(gci),np.amax(gci_rec)))\n",
    "        val = naylor_metrics(gci/maximum, gci_rec/maximum)\n",
    "        \n",
    "        if val[\"identification_rate\"] == -1:\n",
    "            n -= 1\n",
    "            continue\n",
    "\n",
    "        identification_rate_gci += val[\"identification_rate\"]\n",
    "        miss_rate_gci += val[\"miss_rate\"]\n",
    "        false_alarm_rate_gci += val[\"false_alarm_rate\"]\n",
    "        identification_accuracy_gci += val[\"identification_accuracy\"]\n",
    "\n",
    "        maximum = np.amax((np.amax(goi),np.amax(goi_rec)))\n",
    "        val = naylor_metrics(goi/maximum, goi_rec/maximum)\n",
    "        \n",
    "        if val[\"identification_rate\"] == -1:\n",
    "            n -= 1\n",
    "            continue\n",
    "\n",
    "        identification_rate_goi += val[\"identification_rate\"]\n",
    "        miss_rate_goi += val[\"miss_rate\"]\n",
    "        false_alarm_rate_goi += val[\"false_alarm_rate\"]\n",
    "        identification_accuracy_goi += val[\"identification_accuracy\"]\n",
    "\n",
    "        if n==100:\n",
    "            break\n",
    "            \n",
    "for i in k:\n",
    "    if i[:3] == \"slt\":\n",
    "\n",
    "        n += 1\n",
    "\n",
    "        egg,sr_egg = librosa.load(dataset + r\"\\egg\" + \"\\\\\" + i)\n",
    "        speech,_ = librosa.load(dataset + r\"\\speech\" + \"\\\\\" + i)\n",
    "\n",
    "        egg_recreated = reconstruct_egg(speech)\n",
    "        egg = egg[:len(egg_recreated)]\n",
    "\n",
    "        egg_low_pass = butter_lowpass_filter(egg_recreated, cutoff = 1000, fs = sr_egg, order = 6)\n",
    "\n",
    "        gci,goi = get_glottal(egg,sr_egg)\n",
    "        gci_rec,goi_rec = get_glottal(egg_low_pass,sr_egg)\n",
    "\n",
    "        maximum = np.amax((np.amax(gci),np.amax(gci_rec)))\n",
    "        val = naylor_metrics(gci/maximum, gci_rec/maximum)\n",
    "        \n",
    "        if val[\"identification_rate\"] == -1:\n",
    "            n -= 1\n",
    "            continue\n",
    "\n",
    "        identification_rate_gci += val[\"identification_rate\"]\n",
    "        miss_rate_gci += val[\"miss_rate\"]\n",
    "        false_alarm_rate_gci += val[\"false_alarm_rate\"]\n",
    "        identification_accuracy_gci += val[\"identification_accuracy\"]\n",
    "\n",
    "        maximum = np.amax((np.amax(goi),np.amax(goi_rec)))\n",
    "        val = naylor_metrics(goi/maximum, goi_rec/maximum)\n",
    "        \n",
    "        if val[\"identification_rate\"] == -1:\n",
    "            n -= 1\n",
    "            continue\n",
    "\n",
    "        identification_rate_goi += val[\"identification_rate\"]\n",
    "        miss_rate_goi += val[\"miss_rate\"]\n",
    "        false_alarm_rate_goi += val[\"false_alarm_rate\"]\n",
    "        identification_accuracy_goi += val[\"identification_accuracy\"]\n",
    "\n",
    "        if n==150:\n",
    "            break\n",
    "    \n",
    "identification_rate_gci /= n \n",
    "miss_rate_gci /= n \n",
    "false_alarm_rate_gci /= n \n",
    "identification_accuracy_gci /= n \n",
    "\n",
    "identification_rate_goi /= n \n",
    "miss_rate_goi /= n \n",
    "false_alarm_rate_goi /= n \n",
    "identification_accuracy_goi /= n\n",
    "\n",
    "print(\"total time\",time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f55acb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCI\n",
      "Identification Rate:  0.93781897557351\n",
      "Miss Rate:  0.03503558976870273\n",
      "False Alarm Rate:  0.040478767991120254\n",
      "Identification Accuracy:  0.0003761602268740387\n",
      "GOI\n",
      "Identification Rate:  0.9221733773826671\n",
      "Miss Rate:  0.05425677131613817\n",
      "False Alarm Rate:  0.023569851301194114\n",
      "Identification Accuracy:  0.0003761602268740387\n"
     ]
    }
   ],
   "source": [
    "print(\"GCI\")\n",
    "print(\"Identification Rate: \",identification_rate_gci)\n",
    "print(\"Miss Rate: \",miss_rate_gci)\n",
    "print(\"False Alarm Rate: \",false_alarm_rate_gci)\n",
    "print(\"Identification Accuracy: \",identification_accuracy_goi)\n",
    "print(\"GOI\")\n",
    "print(\"Identification Rate: \",identification_rate_goi)\n",
    "print(\"Miss Rate: \",miss_rate_goi)\n",
    "print(\"False Alarm Rate: \",false_alarm_rate_goi)\n",
    "print(\"Identification Accuracy: \",identification_accuracy_goi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af307f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
